{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt \n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "from scipy import stats\n",
    "from statsmodels.regression import linear_model\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State', 'ST', 'Fips', 'County', 'Precincts', 'Votes',\n",
       "       'Less Than High School Diploma', 'At Least High School Diploma',\n",
       "       'At Least Bachelors's Degree', 'Graduate Degree', 'School Enrollment',\n",
       "       'Median Earnings 2010', 'White (Not Latino) Population',\n",
       "       'African American Population', 'Native American Population',\n",
       "       'Asian American Population', 'Other Race or Races', 'Latino Population',\n",
       "       'Children Under 6 Living in Poverty',\n",
       "       'Adults 65 and Older Living in Poverty', 'Total Population',\n",
       "       'Preschool.Enrollment.Ratio.enrolled.ages.3.and.4',\n",
       "       'Poverty.Rate.below.federal.poverty.threshold', 'Gini.Coefficient',\n",
       "       'Child.Poverty.living.in.families.below.the.poverty.line',\n",
       "       'Management.professional.and.related.occupations',\n",
       "       'Service.occupations', 'Sales.and.office.occupations',\n",
       "       'Farming.fishing.and.forestry.occupations',\n",
       "       'Construction.extraction.maintenance.and.repair.occupations',\n",
       "       'Production.transportation.and.material.moving.occupations',\n",
       "       'SIRE_homogeneity', 'median_age', 'Low.birthweight', 'Teen.births',\n",
       "       'Children.in.single.parent.households', 'Adult.smoking',\n",
       "       'Adult.obesity', 'Diabetes', 'Sexually.transmitted.infections',\n",
       "       'HIV.prevalence.rate', 'Uninsured', 'Unemployment', 'Violent.crime',\n",
       "       'Homicide.rate', 'Injury.deaths', 'Infant.mortality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votes= pd.read_csv('votes_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Democrats 08 (Votes)', 'Democrats 12 (Votes)',\n",
       "       'Republicans 08 (Votes)', 'Republicans 12 (Votes)', 'votes16_trumpd',\n",
       "       'votes16_clintonh', 'Fips', 'Democrats08_Voteshare',\n",
       "       'Republicans08_Voteshare', 'Democrats12_Voteshare',\n",
       "       'Republicans12_Voteshare', 'Democrats16_Voteshare',\n",
       "       'Republicans16_Voteshare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_votes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_1 = pd.merge(df,df_votes, on = 'Fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df, df_votes['Republicans08_Voteshare'],df_votes['Democrats08_Voteshare'],\\\n",
    "                    df_votes['Republicans12_Voteshare'],df_votes['Democrats12_Voteshare']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['State','ST','County','Fips'], axis = 1, inplace = True)\n",
    "df_test.drop(['State','ST','County','Fips'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the dataset has been fitted to linear model as shown below.<br>\n",
    "**a. What are the data points?**<br>\n",
    "The data points for the regression here are the counties plotted for each independent variable against Relative vote share.   <br>\n",
    "**b. What are the independent and dependent variables youâ€™ve chosen?**<br>\n",
    "The independent variables are all the columns here in dataframe `df` except the categorical column like state, county and the dependent variable is Relative Vote share from the dataframe `df_1` for the year 2008.<br>\n",
    "\n",
    "**c. Good Measured to evaluate model fit**<br>\n",
    "\n",
    "*R square:* After running the regression, the R square value came out to be 0.669 which means the model takes almost 67% of the variability into consideration. The higher the R square the better fit is your model. So in this case our model explains good variation of our data.   <br>\n",
    "\n",
    "*Adjusted R square:* R square and adjusted R square are very similar except. As we add more variables R square increases however Adjusted R square increases only if the new regressor improves our model. And since we are adding too many regressors in our equation, this would be good measure here as well. In this case the adjusted R square is close to R square value and it actually drops if few independent varibales are removed which means the model we have is a better fit with these variables. <br>\n",
    "\n",
    "*Prob(F-statistic):*The probability of F statistic is another good measure and it shows if the model is good fit than having a model wihtout independent variables or in other words if independent variables imporve the fit of the model. As seen in the summary table, Probability is very low which indicates the model is a better fit. <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(x,y):\n",
    "    x = x.values\n",
    "    X = sm.add_constant(x)\n",
    "    y = y.values\n",
    "    reg = linear_model.OLS(y,X).fit()\n",
    "    print(reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.672\n",
      "Model:                            OLS   Adj. R-squared:                  0.667\n",
      "Method:                 Least Squares   F-statistic:                     147.6\n",
      "Date:                Sun, 28 Apr 2019   Prob (F-statistic):               0.00\n",
      "Time:                        19:56:21   Log-Likelihood:                 3461.5\n",
      "No. Observations:                3141   AIC:                            -6835.\n",
      "Df Residuals:                    3097   BIC:                            -6569.\n",
      "Df Model:                          43                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1139      4.125      0.270      0.787      -6.974       9.202\n",
      "x1         -1.417e-05   2.26e-05     -0.628      0.530   -5.84e-05    3.01e-05\n",
      "x2         -3.242e-07   6.09e-08     -5.322      0.000   -4.44e-07   -2.05e-07\n",
      "x3            -0.0006      0.001     -0.729      0.466      -0.002       0.001\n",
      "x4            -0.0010      0.001     -1.186      0.236      -0.003       0.001\n",
      "x5            -0.0024      0.001     -3.627      0.000      -0.004      -0.001\n",
      "x6            -0.0069      0.001     -6.031      0.000      -0.009      -0.005\n",
      "x7             0.0005      0.000      1.291      0.197      -0.000       0.001\n",
      "x8           -5.9e-07   5.66e-07     -1.043      0.297    -1.7e-06    5.19e-07\n",
      "x9            -0.0031      0.030     -0.105      0.916      -0.062       0.055\n",
      "x10           -0.0088      0.030     -0.295      0.768      -0.067       0.050\n",
      "x11           -0.0095      0.030     -0.317      0.752      -0.068       0.049\n",
      "x12           -0.0093      0.030     -0.311      0.756      -0.068       0.049\n",
      "x13           -0.0114      0.030     -0.381      0.703      -0.070       0.047\n",
      "x14           -0.0085      0.030     -0.283      0.777      -0.067       0.050\n",
      "x15           -0.0005      0.000     -1.754      0.080      -0.001     5.8e-05\n",
      "x16            0.0002      0.000      0.450      0.653      -0.001       0.001\n",
      "x17         8.843e-08    2.4e-08      3.690      0.000    4.14e-08    1.35e-07\n",
      "x18        -8.462e-07      0.000     -0.008      0.994      -0.000       0.000\n",
      "x19           -0.0058      0.001     -5.967      0.000      -0.008      -0.004\n",
      "x20            0.1328      0.060      2.210      0.027       0.015       0.251\n",
      "x21            0.0018      0.001      3.173      0.002       0.001       0.003\n",
      "x22            0.0059      0.029      0.205      0.838      -0.050       0.062\n",
      "x23           -0.0011      0.029     -0.040      0.968      -0.057       0.055\n",
      "x24            0.0036      0.029      0.126      0.899      -0.052       0.060\n",
      "x25            0.0047      0.029      0.165      0.869      -0.051       0.061\n",
      "x26            0.0043      0.029      0.149      0.881      -0.052       0.060\n",
      "x27            0.0002      0.029      0.008      0.993      -0.056       0.056\n",
      "x28           -0.2781      0.019    -14.647      0.000      -0.315      -0.241\n",
      "x29           -0.0061      0.000    -12.270      0.000      -0.007      -0.005\n",
      "x30            0.4438      0.121      3.662      0.000       0.206       0.681\n",
      "x31            0.0014      0.000      9.169      0.000       0.001       0.002\n",
      "x32           -0.2898      0.027    -10.790      0.000      -0.342      -0.237\n",
      "x33           -0.1101      0.033     -3.310      0.001      -0.175      -0.045\n",
      "x34           -0.1224      0.065     -1.894      0.058      -0.249       0.004\n",
      "x35            1.4384      0.134     10.740      0.000       1.176       1.701\n",
      "x36        -1.027e-05   1.08e-05     -0.951      0.342   -3.14e-05    1.09e-05\n",
      "x37        -1.927e-05   9.69e-06     -1.988      0.047   -3.83e-05   -2.69e-07\n",
      "x38            0.9059      0.048     19.048      0.000       0.813       0.999\n",
      "x39           -0.7551      0.071    -10.606      0.000      -0.895      -0.616\n",
      "x40        -9.473e-06   9.76e-06     -0.971      0.332   -2.86e-05    9.65e-06\n",
      "x41           -0.0026      0.001     -3.712      0.000      -0.004      -0.001\n",
      "x42            0.0003   9.38e-05      2.684      0.007    6.78e-05       0.000\n",
      "x43            0.0015      0.001      1.340      0.180      -0.001       0.004\n",
      "==============================================================================\n",
      "Omnibus:                       18.937   Durbin-Watson:                   1.819\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.576\n",
      "Skew:                          -0.131   Prob(JB):                     2.06e-05\n",
      "Kurtosis:                       3.310   Cond. No.                     9.90e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.9e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "regression(df.iloc[:,:],df_1['Republicans08_Voteshare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**<br>\n",
    "After looking at the summary result and considering all these measures, model we have takes a good consideration of our data variance and is a good fit. However there are several things to consider here<br> \n",
    "1. We will have to find out if the model is overfit. Overfitting may arise because of adding too many independent variables and model capturing random noise of our sample rather than reflecting the general trend. Our model should not only fit the current sample, but new samples as well. To find out if our model is overfit, we will have to do train-test split and find out if our model is able to capture a genaral trend from training set and whether it can predict on test set. \n",
    "1. If we take a look at the p-values of the coefficients, only few p-vales are statistically significant and if we delete few non-significant variables from the equation, the R square values actually drops along with adjusted R sqaure. This could be becaus of multicollinearity among the variables. Not all the cariables are needed to build a model however it is not only hard to determine which variables are worth keeping but also time consuming if we keep testing each variable. Multicollinearity affects the coeffiecients and p-values but does not influence the predictions, precision of predictions and the goodness of fit statistics. Since our primary goal here is to fit the model for better predictions and not understand the role of each independent variable, we can use regularization to give importance to important parameters thus reducing the complexity of the model if needed.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Stats model:\n",
    "The following model is logistic regression model using the same demographic data to predict which political party will take the majority of a countyâ€™s votes. (I have used statsmodels package to create your logistic regression model here, not scikit-learn.) \n",
    "### Questions answered:\n",
    "a) How good is the fit of your model? What metric is a good measure to evaluate your model here? Interpret your results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.620330\n",
      "         Iterations 6\n",
      "MSE: 0.006368736603451436\n",
      "RMSE: 0.07980436456392243\n",
      "Predicted 2450 counties vs actual 2235\n"
     ]
    }
   ],
   "source": [
    "x = df.iloc[:,:].values\n",
    "X = sm.add_constant(x)\n",
    "Y = df_1['Republicans08_Voteshare'].values\n",
    "logit = sm.Logit(Y, X)\n",
    "\n",
    "fitted_model = logit.fit()\n",
    "\n",
    "prediction = fitted_model.predict(X)\n",
    "print('MSE: '+str(np.mean((prediction-Y)**2)))\n",
    "print('RMSE: '+str(sqrt(np.mean((prediction-Y)**2))))\n",
    "print('Predicted '+str(prediction[prediction>0.5].size)+' counties vs actual '+ str(Y[Y>0.5].size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measure of a good fit and Interpretation:**<br>\n",
    "To measure the good fit of the model either Mean Square Error or Root Mean Square error would be good metrics as they measure the variance in the predicted y values and actual. RMSE can be easily interpreted a standard deviation of the error and it has the same unit as the response variable, in our case relative vote share unit. Closer the values to zero better is the fit of our model.<br>\n",
    "The model above predicts Republican party to take the majority of the votes. As shown above, model predicted 2450 counties with more than 50% Republic party vote share which is higher than the actual count 2250.<br>\n",
    "The count does not indicate if our model is a better fit to the data points. MSE and RMSE values for the model are very low which indicates our model is good fit.\n",
    "However the data we trained the model on acts as test data above for prediction which it is not a good to measure our model. The model needs to see new data to draw any strong conclusion about the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modelling:\n",
    "I built new models to predict the 2012 and 2016 relative vote share of the Republican party, respectively.\n",
    "### Questions answered:\n",
    "How does each of their performances compare to 2008 Linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 2012 model, Votes column has been replaced with the total number of votes for 2012 although it had almost no impact on the result after testing. As the model shows below the R square and adjusted R square values are better than 2008 model. The 2012 model takes more variability into account than 2008. However it is not sure if the model is overfit and is not able to predict on the new data.<br>\n",
    "To find out if the model is overfit, train-test split method  has been used. The model shows similar R square value on the test set as train set meaning the model is able to capture the genreal trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['Total_votes_12'] = df_1['Republicans 12 (Votes)'] + df_1['Democrats 12 (Votes)']\n",
    "df['Votes'] = df_1['Total_votes_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.715\n",
      "Model:                            OLS   Adj. R-squared:                  0.711\n",
      "Method:                 Least Squares   F-statistic:                     180.3\n",
      "Date:                Sun, 28 Apr 2019   Prob (F-statistic):               0.00\n",
      "Time:                        19:56:30   Log-Likelihood:                 3468.0\n",
      "No. Observations:                3141   AIC:                            -6848.\n",
      "Df Residuals:                    3097   BIC:                            -6582.\n",
      "Df Model:                          43                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5089      4.117      0.367      0.714      -6.563       9.581\n",
      "x1         -7.564e-06   2.25e-05     -0.336      0.737   -5.17e-05    3.66e-05\n",
      "x2         -4.243e-07   7.44e-08     -5.703      0.000    -5.7e-07   -2.78e-07\n",
      "x3            -0.0008      0.001     -0.884      0.377      -0.002       0.001\n",
      "x4            -0.0015      0.001     -1.882      0.060      -0.003    6.31e-05\n",
      "x5            -0.0024      0.001     -3.537      0.000      -0.004      -0.001\n",
      "x6            -0.0076      0.001     -6.646      0.000      -0.010      -0.005\n",
      "x7             0.0002      0.000      0.697      0.486      -0.000       0.001\n",
      "x8         -7.508e-07   5.65e-07     -1.330      0.184   -1.86e-06    3.56e-07\n",
      "x9            -0.0090      0.030     -0.300      0.764      -0.067       0.049\n",
      "x10           -0.0155      0.030     -0.522      0.602      -0.074       0.043\n",
      "x11           -0.0157      0.030     -0.527      0.598      -0.074       0.043\n",
      "x12           -0.0150      0.030     -0.504      0.614      -0.073       0.043\n",
      "x13           -0.0185      0.030     -0.621      0.535      -0.077       0.040\n",
      "x14           -0.0149      0.030     -0.500      0.617      -0.073       0.044\n",
      "x15           -0.0003      0.000     -1.082      0.279      -0.001       0.000\n",
      "x16           -0.0004      0.000     -0.912      0.362      -0.001       0.000\n",
      "x17         1.251e-07   2.83e-08      4.417      0.000    6.96e-08    1.81e-07\n",
      "x18        -5.431e-05      0.000     -0.483      0.629      -0.000       0.000\n",
      "x19           -0.0059      0.001     -6.043      0.000      -0.008      -0.004\n",
      "x20            0.1889      0.060      3.152      0.002       0.071       0.306\n",
      "x21            0.0017      0.001      3.013      0.003       0.001       0.003\n",
      "x22            0.0087      0.029      0.304      0.761      -0.047       0.065\n",
      "x23            0.0018      0.029      0.063      0.950      -0.054       0.058\n",
      "x24            0.0060      0.029      0.212      0.832      -0.050       0.062\n",
      "x25            0.0067      0.029      0.233      0.816      -0.049       0.063\n",
      "x26            0.0069      0.029      0.243      0.808      -0.049       0.063\n",
      "x27            0.0029      0.029      0.101      0.920      -0.053       0.059\n",
      "x28           -0.2570      0.019    -13.559      0.000      -0.294      -0.220\n",
      "x29           -0.0062      0.000    -12.582      0.000      -0.007      -0.005\n",
      "x30            0.5164      0.121      4.270      0.000       0.279       0.754\n",
      "x31            0.0014      0.000      8.924      0.000       0.001       0.002\n",
      "x32           -0.3297      0.027    -12.300      0.000      -0.382      -0.277\n",
      "x33           -0.1287      0.033     -3.874      0.000      -0.194      -0.064\n",
      "x34           -0.0807      0.064     -1.252      0.211      -0.207       0.046\n",
      "x35            1.3291      0.134      9.942      0.000       1.067       1.591\n",
      "x36        -1.057e-05   1.08e-05     -0.981      0.327   -3.17e-05    1.06e-05\n",
      "x37        -2.319e-05   9.66e-06     -2.399      0.016   -4.21e-05   -4.24e-06\n",
      "x38            0.9552      0.047     20.129      0.000       0.862       1.048\n",
      "x39           -0.7565      0.071    -10.647      0.000      -0.896      -0.617\n",
      "x40        -1.288e-05   9.73e-06     -1.324      0.186   -3.19e-05    6.19e-06\n",
      "x41           -0.0020      0.001     -2.963      0.003      -0.003      -0.001\n",
      "x42            0.0004   9.37e-05      4.248      0.000       0.000       0.001\n",
      "x43            0.0015      0.001      1.310      0.190      -0.001       0.004\n",
      "==============================================================================\n",
      "Omnibus:                       20.193   Durbin-Watson:                   1.810\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.586\n",
      "Skew:                          -0.144   Prob(JB):                     1.25e-05\n",
      "Kurtosis:                       3.300   Cond. No.                     9.92e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.92e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "regression(df.iloc[:,:],df_1['Republicans12_Voteshare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train(x,y):\n",
    "    x = x.values\n",
    "    X = sm.add_constant(x)\n",
    "    y = y.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "    my_reg = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "    y_train_predicted = my_reg.predict(X_train)\n",
    "\n",
    "    y_test_predicted = my_reg.predict(X_test)\n",
    "\n",
    "    print(sklearn.metrics.r2_score(y_train, y_train_predicted))\n",
    "    print(sklearn.metrics.r2_score(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7136437963819189\n",
      "0.7090432864600528\n"
     ]
    }
   ],
   "source": [
    "test_train(df.iloc[:,:],df_1['Republicans12_Voteshare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2016 Model:**<br>\n",
    "2016 model seems to consider even more variabiltiy and fit well with the data. Test-train split result shows the model is not overfit as well. The Adjusted R square has also increased. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['Total_votes_16'] = df_1['votes16_trumpd'] + df_1['votes16_clintonh']\n",
    "df['Votes'] = df_1['Total_votes_16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.809\n",
      "Model:                            OLS   Adj. R-squared:                  0.806\n",
      "Method:                 Least Squares   F-statistic:                     305.3\n",
      "Date:                Sun, 28 Apr 2019   Prob (F-statistic):               0.00\n",
      "Time:                        19:56:43   Log-Likelihood:                 3880.8\n",
      "No. Observations:                3141   AIC:                            -7674.\n",
      "Df Residuals:                    3097   BIC:                            -7407.\n",
      "Df Model:                          43                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.5702      3.610     -0.435      0.664      -8.648       5.507\n",
      "x1         -1.526e-05   1.97e-05     -0.773      0.440    -5.4e-05    2.34e-05\n",
      "x2         -3.052e-07   5.52e-08     -5.524      0.000   -4.14e-07   -1.97e-07\n",
      "x3            -0.0004      0.001     -0.494      0.621      -0.002       0.001\n",
      "x4            -0.0002      0.001     -0.217      0.828      -0.002       0.001\n",
      "x5            -0.0056      0.001     -9.559      0.000      -0.007      -0.004\n",
      "x6            -0.0078      0.001     -7.877      0.000      -0.010      -0.006\n",
      "x7             0.0004      0.000      1.377      0.169      -0.000       0.001\n",
      "x8          -5.81e-07   4.95e-07     -1.173      0.241   -1.55e-06     3.9e-07\n",
      "x9             0.0083      0.026      0.319      0.750      -0.043       0.060\n",
      "x10            0.0006      0.026      0.024      0.981      -0.051       0.052\n",
      "x11            0.0019      0.026      0.071      0.943      -0.049       0.053\n",
      "x12            0.0019      0.026      0.072      0.943      -0.049       0.053\n",
      "x13           -0.0012      0.026     -0.048      0.962      -0.053       0.050\n",
      "x14            0.0021      0.026      0.081      0.936      -0.049       0.053\n",
      "x15           -0.0002      0.000     -0.888      0.375      -0.001       0.000\n",
      "x16        -3.082e-05      0.000     -0.075      0.940      -0.001       0.001\n",
      "x17         7.649e-08   2.08e-08      3.677      0.000    3.57e-08    1.17e-07\n",
      "x18        -4.666e-05   9.87e-05     -0.473      0.636      -0.000       0.000\n",
      "x19           -0.0042      0.001     -4.910      0.000      -0.006      -0.003\n",
      "x20            0.1437      0.053      2.733      0.006       0.041       0.247\n",
      "x21            0.0014      0.001      2.827      0.005       0.000       0.002\n",
      "x22            0.0212      0.025      0.848      0.397      -0.028       0.070\n",
      "x23            0.0156      0.025      0.621      0.535      -0.034       0.065\n",
      "x24            0.0180      0.025      0.718      0.473      -0.031       0.067\n",
      "x25            0.0190      0.025      0.759      0.448      -0.030       0.068\n",
      "x26            0.0194      0.025      0.775      0.439      -0.030       0.069\n",
      "x27            0.0165      0.025      0.659      0.510      -0.033       0.066\n",
      "x28           -0.2399      0.017    -14.441      0.000      -0.272      -0.207\n",
      "x29           -0.0042      0.000     -9.756      0.000      -0.005      -0.003\n",
      "x30            0.5301      0.106      4.999      0.000       0.322       0.738\n",
      "x31            0.0012      0.000      9.075      0.000       0.001       0.001\n",
      "x32           -0.2735      0.024    -11.638      0.000      -0.320      -0.227\n",
      "x33           -0.0298      0.029     -1.022      0.307      -0.087       0.027\n",
      "x34           -0.0164      0.057     -0.290      0.772      -0.127       0.094\n",
      "x35            1.1085      0.117      9.459      0.000       0.879       1.338\n",
      "x36        -1.757e-05   9.45e-06     -1.859      0.063   -3.61e-05    9.66e-07\n",
      "x37        -5.787e-06   8.48e-06     -0.682      0.495   -2.24e-05    1.08e-05\n",
      "x38            0.7006      0.042     16.833      0.000       0.619       0.782\n",
      "x39           -0.8173      0.062    -13.119      0.000      -0.939      -0.695\n",
      "x40        -2.237e-05   8.54e-06     -2.621      0.009   -3.91e-05   -5.63e-06\n",
      "x41           -0.0014      0.001     -2.326      0.020      -0.003      -0.000\n",
      "x42            0.0002    8.2e-05      2.270      0.023    2.54e-05       0.000\n",
      "x43            0.0021      0.001      2.152      0.031       0.000       0.004\n",
      "==============================================================================\n",
      "Omnibus:                       91.550   Durbin-Watson:                   1.824\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              132.440\n",
      "Skew:                          -0.301   Prob(JB):                     1.74e-29\n",
      "Kurtosis:                       3.806   Cond. No.                     9.84e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.84e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "regression(df.iloc[:,:],df_1['Republicans16_Voteshare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8042515646865074\n",
      "0.8165592072243069\n"
     ]
    }
   ],
   "source": [
    "test_train(df.iloc[:,:],df_1['Republicans16_Voteshare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: \n",
    "As the comparison table shows below, the model has improved for every election year. Considering the fact that, the independent variables were not changed and every election year more counties are voting for Republic party, the variance is less in the data set every year, the model seems to reflect this information and is a good fit of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    Metrics   \t| 2008 \t| 2012 \t| 2016 \t|\n",
    "|:------------:\t|:----:\t|:----:\t|:----:\t|\n",
    "|   R sqaure   \t| 0.67 \t| 0.71 \t| 0.80 \t|\n",
    "|  Adj sqaure  \t| 0.66 \t| 0.71 \t| 0.80 \t|\n",
    "| Prob(F-stat) \t| 0.00 \t| 0.00 \t| 0.00 \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if adding the historical performance improves our model. For 2016 model, we will use the 2008 and 2012 Republicans and Democrats vote share data as independent variables. The data frame `df_test_2` was created above with these columns and will be analyzed. <br>\n",
    "As shown below the model captures 97% variance and the adjusted R suqare is similar to R square. The test-train split also shows the model is not overfit. The standard error values for coefficients shows that the data points are very close to the regression line explaining better fit of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.975\n",
      "Model:                            OLS   Adj. R-squared:                  0.974\n",
      "Method:                 Least Squares   F-statistic:                     2661.\n",
      "Date:                Sun, 28 Apr 2019   Prob (F-statistic):               0.00\n",
      "Time:                        19:56:54   Log-Likelihood:                 7061.0\n",
      "No. Observations:                3141   AIC:                        -1.403e+04\n",
      "Df Residuals:                    3095   BIC:                        -1.375e+04\n",
      "Df Model:                          45                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.2210      0.656     -1.861      0.063      -2.507       0.065\n",
      "x1         -3.711e-06   7.17e-06     -0.517      0.605   -1.78e-05    1.04e-05\n",
      "x2         -6.868e-08   1.95e-08     -3.529      0.000   -1.07e-07   -3.05e-08\n",
      "x3             0.0002      0.000      0.885      0.376      -0.000       0.001\n",
      "x4             0.0010      0.000      4.027      0.000       0.001       0.002\n",
      "x5            -0.0036      0.000    -16.950      0.000      -0.004      -0.003\n",
      "x6            -0.0016      0.000     -4.505      0.000      -0.002      -0.001\n",
      "x7             0.0002      0.000      1.756      0.079    -2.3e-05       0.000\n",
      "x8          7.348e-08    1.8e-07      0.408      0.683    -2.8e-07    4.26e-07\n",
      "x9             0.0163      0.009      1.715      0.086      -0.002       0.035\n",
      "x10            0.0139      0.009      1.466      0.143      -0.005       0.033\n",
      "x11            0.0153      0.009      1.612      0.107      -0.003       0.034\n",
      "x12            0.0147      0.009      1.547      0.122      -0.004       0.033\n",
      "x13            0.0145      0.010      1.530      0.126      -0.004       0.033\n",
      "x14            0.0149      0.009      1.564      0.118      -0.004       0.033\n",
      "x15         3.856e-05   8.93e-05      0.432      0.666      -0.000       0.000\n",
      "x16            0.0003      0.000      1.707      0.088   -3.81e-05       0.001\n",
      "x17         1.809e-08   7.64e-09      2.368      0.018    3.11e-09    3.31e-08\n",
      "x18         -6.22e-06   3.59e-05     -0.173      0.862   -7.66e-05    6.41e-05\n",
      "x19            0.0006      0.000      2.063      0.039    3.19e-05       0.001\n",
      "x20           -0.0096      0.019     -0.500      0.617      -0.047       0.028\n",
      "x21        -3.426e-07      0.000     -0.002      0.999      -0.000       0.000\n",
      "x22            0.0141      0.009      1.548      0.122      -0.004       0.032\n",
      "x23            0.0140      0.009      1.538      0.124      -0.004       0.032\n",
      "x24            0.0129      0.009      1.423      0.155      -0.005       0.031\n",
      "x25            0.0136      0.009      1.489      0.137      -0.004       0.031\n",
      "x26            0.0136      0.009      1.497      0.135      -0.004       0.031\n",
      "x27            0.0141      0.009      1.549      0.121      -0.004       0.032\n",
      "x28           -0.0306      0.006     -4.894      0.000      -0.043      -0.018\n",
      "x29            0.0009      0.000      5.396      0.000       0.001       0.001\n",
      "x30            0.1078      0.039      2.788      0.005       0.032       0.184\n",
      "x31            0.0001   4.93e-05      2.207      0.027    1.22e-05       0.000\n",
      "x32           -0.0049      0.009     -0.558      0.577      -0.022       0.012\n",
      "x33            0.0752      0.011      7.083      0.000       0.054       0.096\n",
      "x34            0.0474      0.021      2.305      0.021       0.007       0.088\n",
      "x35            0.0043      0.043      0.100      0.921      -0.081       0.089\n",
      "x36        -8.535e-06   3.44e-06     -2.484      0.013   -1.53e-05    -1.8e-06\n",
      "x37         1.143e-05   3.08e-06      3.705      0.000    5.38e-06    1.75e-05\n",
      "x38           -0.0870      0.016     -5.400      0.000      -0.119      -0.055\n",
      "x39           -0.2008      0.023     -8.707      0.000      -0.246      -0.156\n",
      "x40        -1.175e-05    3.1e-06     -3.787      0.000   -1.78e-05   -5.67e-06\n",
      "x41            0.0003      0.000      1.327      0.185      -0.000       0.001\n",
      "x42           -0.0001      3e-05     -3.978      0.000      -0.000   -6.05e-05\n",
      "x43            0.0009      0.000      2.605      0.009       0.000       0.002\n",
      "x44           -0.5874      0.328     -1.790      0.074      -1.231       0.056\n",
      "x45           -0.6337      0.328     -1.932      0.054      -1.277       0.010\n",
      "x46           -0.2251      0.328     -0.686      0.493      -0.868       0.418\n",
      "x47           -0.9959      0.328     -3.035      0.002      -1.639      -0.352\n",
      "==============================================================================\n",
      "Omnibus:                      497.000   Durbin-Watson:                   1.756\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7304.953\n",
      "Skew:                           0.243   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.455   Cond. No.                     1.08e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.22e-18. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "regression(df_test.iloc[:,:],df_1['Republicans16_Voteshare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748020699359016\n",
      "0.9743675091077355\n"
     ]
    }
   ],
   "source": [
    "test_train(df_test.iloc[:,:],df_1['Republicans16_Voteshare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
